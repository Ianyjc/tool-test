import { HumanMessage, ToolMessage } from "@langchain/core/messages";
import { MultiServerMCPClient } from "@langchain/mcp-adapters";
import { ChatOpenAI } from "@langchain/openai";
import chalk from "chalk";

const model = new ChatOpenAI({
  modelName: "qwen-plus",
  apiKey: 'sk-26e8025b7fa64b369bb88b981e836ff0',
  configuration: {
    baseURL: 'https://dashscope.aliyuncs.com/compatible-mode/v1',
  },
});

const mcpClient = new MultiServerMCPClient({
  mcpServers: {
    "my-mcp-server": {
      command: "node",
      args: ["/Users/ianyi/ai-tool-test/src/my-mcp-server.mjs"],
    },
  },
});

const tools = await mcpClient.getTools();
const modelWithTools = model.bindTools(tools);

async function runAgentWithTools(query, maxIterations = 30) {
  const messages = [new HumanMessage(query)];

  for (let i = 0; i < maxIterations; i++) {
    console.log(chalk.bgGreen(`‚è≥ Ê≠£Âú®Á≠âÂæÖ AI ÊÄùËÄÉ...`));
    const response = await modelWithTools.invoke(messages);
    messages.push(response); // Ê£ÄÊü•ÊòØÂê¶ÊúâÂ∑•ÂÖ∑Ë∞ÉÁî®

    if (!response.tool_calls || response.tool_calls.length === 0) {
      console.log(`\n‚ú® AI ÊúÄÁªàÂõûÂ§ç:\n${response.content}\n`);
      return response.content;
    }

    console.log(
      chalk.bgBlue(`üîç Ê£ÄÊµãÂà∞¬†${response.tool_calls.length}¬†‰∏™Â∑•ÂÖ∑Ë∞ÉÁî®`)
    );
    console.log(
      chalk.bgBlue(
        `üîç Â∑•ÂÖ∑Ë∞ÉÁî®:¬†${response.tool_calls.map((t) => t.name).join(", ")}`
      )
    );

    for (const toolCall of response.tool_calls) {
      const foundTool = tools.find((t) => t.name === toolCall.name);
      if (foundTool) {
        const toolResult = await foundTool.invoke(toolCall.args);

        messages.push(
          new ToolMessage({
            content: toolResult,
            tool_call_id: toolCall.id,
          })
        );
      }
    }
  }

  return messages[messages.length - 1].content;
}

await runAgentWithTools("Êü•ËØ¢‰∏Ä‰∏ãÁî®Êà∑ 002 ÁöÑ‰ø°ÊÅØ");

await mcpClient.close();